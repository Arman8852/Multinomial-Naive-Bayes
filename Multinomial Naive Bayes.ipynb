{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "2QjPY4fUO1rb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/spam.csv', encoding='latin1',  index_col=False)"
      ],
      "metadata": {
        "id": "CPJPbAOcO_hz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0JVghzoNvcx"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "  if row['v1'] == 'ham':\n",
        "    with open('/ham.txt', 'a') as file:\n",
        "      file.write(row['v2'] + ' ')\n",
        "  else:\n",
        "    with open('/spam.txt', 'a') as file:\n",
        "      file.write(row['v2'] + ' ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class unique_words_lower_case():\n",
        "\n",
        "  def __init__(self, ham_text_file, spam_text_file):\n",
        "    self.ham_text_file = ham_text_file\n",
        "    self.spam_text_file = spam_text_file\n",
        "\n",
        "    self.ham_text, self.ham_word_count, self.ham_sentence_count = self.extract_text(self.ham_text_file)\n",
        "    self.spam_text, self.spam_word_count, self.spam_sentence_count = self.extract_text(self.spam_text_file)\n",
        "\n",
        "    self.join_text = self.ham_text + ' ' + self.spam_text\n",
        "    self.ham_unique_words = self.unique_words(self.ham_text)\n",
        "\n",
        "    self.unique_words = self.unique_words(self.join_text)\n",
        "\n",
        "    self.ham_word_percentage = self.word_percentage(self.ham_text, self.ham_word_count)\n",
        "    self.spam_word_percentage = self.word_percentage(self.spam_text, self.spam_word_count)\n",
        "\n",
        "  def extract_text(self, text_file):\n",
        "    with open(text_file, 'r') as file:\n",
        "      text = file.read()\n",
        "      text = text.lower()\n",
        "    sentence = len(text.lower().split('. '))\n",
        "    word_count = len(text.lower().split())\n",
        "    return text, word_count, sentence\n",
        "\n",
        "  def unique_words(self, text):\n",
        "    words = text.lower().split()\n",
        "    unique_words = []\n",
        "\n",
        "    for word in words:\n",
        "      if re.match(\"\\W([A-Za-z]*)\", word):\n",
        "        word = re.match(\"\\W([A-Za-z]*)\", word).group(1)\n",
        "\n",
        "      elif re.match(\"([A-Za-z]*)\\W\", word):\n",
        "        word = re.match(\"([A-Za-z]*)\\W\", word).group(1)\n",
        "\n",
        "      word = word + ' '\n",
        "      unique_words.append(word)\n",
        "\n",
        "    unique_words = set(unique_words)\n",
        "    return unique_words\n",
        "\n",
        "  def word_percentage(self, text, word_count):\n",
        "    percent_dict = {}\n",
        "    for word in self.unique_words:\n",
        "      key = word.rstrip()\n",
        "      percent_dict[key] = (text.replace('.', ' ').lower().count(word) + 1) / word_count\n",
        "    return percent_dict\n",
        "\n",
        "  def predict_lebel(self, text):\n",
        "    ham_probability = self.ham_sentence_count / (self.ham_sentence_count + self.spam_sentence_count)\n",
        "    spam_probability = self.spam_sentence_count / (self.ham_sentence_count + self.spam_sentence_count)\n",
        "    for word in text.lower().split():\n",
        "      ham_probability *= self.ham_word_percentage[word]\n",
        "      spam_probability *= self.spam_word_percentage[word]\n",
        "\n",
        "    if ham_probability > spam_probability:\n",
        "      return 'Ham'\n",
        "    else:\n",
        "      return 'Spam'"
      ],
      "metadata": {
        "id": "wTFSYpmIOaib"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_unique_words = unique_words_lower_case('/ham.txt', '/spam.txt')"
      ],
      "metadata": {
        "id": "oYNJdixwOcA7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string_to_unique_words.predict_lebel('''Free entry in 2 a wkly comp to win FA Cup final tkts'''))\n",
        "print(string_to_unique_words.predict_lebel('''Available only in bugis n great world la e buffet'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj99_EPVOevH",
        "outputId": "2f765b63-72a8-47bc-8ae1-fd0df1af27f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam\n",
            "Ham\n"
          ]
        }
      ]
    }
  ]
}